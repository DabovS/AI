# AI 
# Primer Concepts
Since the invention of computers or machines, their capability to perform various tasks has experienced an exponential growth. Humans have developed the power of computer systems in terms of their diverse working domains, their incresing speed, and reducing size with respect to time.

A branch of Computer Science named Artificial Intelligence pursues creating the computers or machines as intelligent as human beings.

## Basic Concept of Artificial Intelligence (AI)
According to the father of Artificial Intelligence, John McCarthy, it is "The sceince and engineering of making intelligent machines, especially intelligent computer programs". 

Artificail Intelligence is a way of making a computer, a computer-controlled robot, or a software think intelligently, in the similar manner to intelligent human think. AI is accomplished by studying how human brain thinks and how humans learn, decide, and work while trying to solve a problem, and then using the ourcomes of this study as a basis of developing intelligent software and systems.

While exploiting the power of AI started with intention of creating similar intelligence in machines that we find and regard high in humans.

## The Necessity of Learning AI
As we know that AI purues creating the machines as intelligent as human beings. There are numerous reasons for us to study AI. The reasons are as follows -

### AI can learn through data
In our daily life, we deal with huge amount of data and human brain cannot keep track of so much data. That is why we need to automate the things. For doing automation, we need to study AI because it can learn from data and can do the repetitive tasks with accuracy and without tiredness.

### AI can teach itself
It is very necessary that a system should teach itself because the data itself keeps changing and the knowledge which is derived from such data must be updated constantly. We can use AI to fulfill this purpose because an AI enabled system can teach itself.

### AI can respond in real time
Artificial intelligence with the help of neural networks can analyze the data more deeply. Due to this capability, AI can think and respond to the situations which are based on the conditions in real time.

### AI achieves accuracy
With the help of deep neural networks, AI can acieve tremendous accuracy. AI helps in the field of medicine to diagnose diseases such as cancer from the MRIs of patients.

### AI can organize data to get most out of it
The data is an intellectual property for the system which are using self-learning algorithms. We need AI to index and organize the data in a way that it always gives the best results.

### Understanding Intelligence
With AI, smart systems can be built. We need to undestand the concept of intelligence so that our brain can construct another intelligence system like itself.

## What is Intelligence?
The ability of a system to calculate, reason, perceive relationships and analogies, learn from experience, store and retrieve information from memory, solve problems, comprehend complex ideas, use natural language fluently, classify, generalize, and adapt new situations.

| Sr.No | Intelligence & Description | Example |
--- | --- | --- |
|1 | **Linguistic intelligence**. The ability to speak, recognize, and use mechanisms of phonology (speech sounds), syntax (grammar), and semantics (meaning). | Narrators, Operators | 
| 2 | **Musical intelligence**. The ability to create, communicate with, and undestand meanings made of sound, understanding of pitchm rhythm. | Musicians, Singers, Composers |
| 3 | **Logical-mathemetical intelligence**. The ability to use and undestand relationships in the absence of action or objects. It is also the ability to understand complex and abstract ideas. | Mathematicians, Scientists |
| 4 | **Spatial intelligence**. The ability to perceive visual or spacial information, change it, and re-create visual images without reference to the objects, construct 3D images, and to move and rotate them. | Map readers, Astronauts, Physicists |
| 5 | **Bodily-Kinesthetic intelligence**. The abiility to use complete or part of the body to solve problems or fashion products, control over fine and coarse motor skills, and manipulate the objects. | Players, Dancers |
| 6 | **Intra-personal intelligence**. The ability to distinguish among one's own feelings, intentions, and motivations. | Gautam Buddhha |
| 7 | **Interpersonal intelligence**. The ability to recognize and make distinctions among other people's feelings, beliefs, and intentions. | Mass Communicators, Interviewers |

You can say a machine or a system is artificially intelligent when it is equipped with a least one or all intelligence in it.

## What is Intelligence Composed Of?
The intelligence is intangible. It is composed of:

* Reasonning
* Learning
* Problem Solving 
* Perception
* Linguistic Intelligence

![01 Intelligence](https://user-images.githubusercontent.com/124214430/222724983-0eb6649d-36ca-4039-b3f4-60d8169180a2.png)

### Reasoning
It is the set of processes that enables us to provide besis for judgement, making decisions, and prediction. There are broadly two types:

1. [**Inductive Reasoning**](https://www.scribbr.com/methodology/inductive-reasoning/)

* It conducts specific observations to makes broad general statements. 
* Even if all of the premises are true in a statement, inductive reasoning allows for the conclusion to be false.

**Example**: "Nita is a teacher, Nita is studious. Therefore, All teachers are studious." 

2. [**Deductive Reasoning**](https://www.scribbr.com/methodology/deductive-reasoning/)

* It starts with a general statement and examines the possibilities to reach a specific, logical conclusion.
* If something is true of a class of things in general, it is also true for all members of that class.

**Example**: "All women of age above 60 years are grandmothers. Shalini is 65 years. Therefore, Shalini is a grandmother."

### Learning - 1
The ability of learning is prossessed by humans, particular species of animals, and AI-enabled systems. Learning is categorized as follows:

1. **Auditory Learning**

* It is learning by listening and hearing. For example, students listening to recorded audio lectures.

2. **Episodic Learning**

* To learn by remembering sequences of events that one has witnessed or experienced. This is linear and orderly.

3. **Motor Learning**

* It is learning by precise movement of muscles. For example, picking objects, writing, etc.

4. **Observational Learning**

* To learn by watching and imitating others. For example, child tries to learn by mimicking her parent.

5. **Perceptual Larning**

* It is learning to recognize stimuli that one has seen before. For example, identifying and classifying objects and situations.

6. **Relational Learning**

* It involves learning to differentiate among various stimuli on the basis of relational properties, rather than absolute properties. For Example, Adding 'little less' salt at the time of cooking potatoes that came up salty last time, when cooked with adding say a tablespoon of salt.

    * **Spatial Learning** - It is learning through visual stimuli such as images, colors, maps, etc. For example, A person can create roadmap in mind before actually following the road.
    * **Stimulus-Response Learning** - It is learning to perform a particular behavior when a certain stimulus is present. For example, a dog raises its ear on hearing doorbell.

7. **Problem Solving**

* It is the process in which one perceives and tries to arrive at a desired solution from a present situation by taking some path, which is blocked by known or unknown hurdles.
* Problem solving also includes **decision making**, which is the process of selecting the best suitable alternative out of multiple alternatives to reach the desired goal. 

8. **Perception**

* It is the process of aquiring, interpreting, selecting, and organizing sensory information.
* Perception presumes **sensing**. In humans, perception is aided by sensory organs. In the domain of AI, perception mechanism puts the data aquired by the sensors together in a meaningful manner.

9. **Linguistic Intelligence**

* It is one's ability to use, comprehend, speak, and write the verbal and written language. It is important in interpersonal communication.

## What's Involved in AI
Artificial intelligence is a vast area of study. This field of study helps in finding solutions to real world problems. Let us now see the different fields of study within AI:

1. **Machine Learning**

* It is one of the most popular fields of AI. The basic concept of this field is to make the machine learning from data as the human beings can learn from his/her experience. It contains learning models on the basis of which the predictions can be made on unknown data.

2. **Logic**

* It is another important field of study in which mathematical logic is used to execute the computer programs. It contains rules and facts to perform pattern matching, semantic analysis, etc.

3. **Searching**

* This field of study is basically used in games like chess, tic-tac-toe. Search algorithms give the optimal solution after searching the whole search space.

4. **Artificial neural networks**

* This is a network of efficient computing systems the central theme of which is borrowed from the analogy of biological neural networks. ANN can be used in robotics, speech recognition, speech processing, etc.

5. **Genetic Algorithm**

* Genetic algorithms help in solving problems with the assistance of more than one program. The result would be besed on selectinmg the fittest.

6. **Knowledge Representation**

* It is the field of study with the help of which we can represent the facts in a way the machine that is undestandable to the machine. The more efficiently knowledge is represented, the more system would be intelligent.

## Application of AI
In this section, we will see  the different fields supported by AI.

1. **Gaming**

* AI plays crucial role in strategic games such as chess, poker, tic-tac-toe, etc., where machine can think of large number of possibile positions based on heuristic knowledge.

2. **Natural Language Processing**

* It is possible to interact with the computer that understand natural language spoken by humans.

3. **Expert Systems**

* There are some appluications which integrate machine, software, and special information to impact reasoning and advising. They provide explanation and advice to the users.

4. **Vision Systems**

* Thease systems understand, interpret, and comprehend visual input on the computer. For example:
    * A spying aeroplane takes photohraphs, which are used to figure out spatial information or map of the areas.
    * Doctors use clinical expert system to diagnose the patient.
    * Police use computer software that can recognize the face of criminal with the stored portrait made by forensic artist.

5. **Speech Recognition**

* Some intelligent systems are capable of hearing and comprehending thelanguage in terms of sentences and their meanings while a human talks to it. It can handle different accents, slang words, noise in the background, change in human's noise due to cold, etc.

6. **Handwriting Recognition**

* The handwriting recognition software reads the text written on paper by a pen or on screen by a stylus. It can recognize the shapes of the letters and convert it into editable text.

7. **Intelligent Robots**

* Robots are able to perform the tasks given by a human. They have sensors to detect physical data from the real world such as light, heat, temperature, movement, sound, bump, and presure. They have efficient processors, multiple sensors and huge memory, to exhibit intelligence. In addition, they are capable of learning from their mistakes and the can adapt to the new environment. 

## Cognitive Modeling: Simulating Human Thinking Procedure
Cognitive modeling is basically the field of study within computer science that edals with the study and simulating the thinking process of human beings. The main task of AI is to make machine think like human. The most important feature of human thinking process is problem solving. That is why more or less cognitive modeling tries to undestand how humans can solve the problems. After that this model can be used for various AI applications such as machine learning, robotics, natural language processing, etc. Following is the diagram of different thinking levels of human brain:

![02 Brain](https://user-images.githubusercontent.com/124214430/222725005-3b196c64-c3db-45b0-9744-5579ac279b21.png)

## Agent & Environment
In this section, we will focus on the agent and environment and how these help in Artificial Intelligence.

### Agent
An agent is anything that can perceive its environment through sensors and act upon that environment through effectors.

* A **human agent** has sensory organs such as eyes, ears, nose, tongue and skin parallel to the sensors, and other organs such as hand, legs, mouth, for effectors. 
* A **robotic agent** replaces cameras and intrared range finders for the sensors, and various motors and actuators for effectors. 
* A **software agent** has encoded bit strings as its programs and actions. 

### Environment
Some programs operate in an entirely **artificial environment** confined to keyboard input, database, computer file systems and character output on a screen. 

In contrast, some software agents (software robots or softbots) exist in rich, unlimited softbots domains. The simulator has a **very detailed, complex environment**. The software agent needs to choose from a long array of actions in real time. A softbot is designed to scan online preferences of the customer and shows interesting items to the customer works in the **real** as well as an **artificial** environment.

# Getting Started
In this chapter, we will learn how to get started with Python. We will also undestand how Python helps for Artificial Intelligence.

## Why Python for AI
Artificial intelligence is considered to be the trending technology of the future. Already there are a number of applications made on it. Due to this, many companies and researchers are taking interest in it. But the main question that arises here is that in which programming language can these AI applications be developed? There are various programming languages like Lisp, Prolog, C++, Java and Python, which can be used for developing applications of AI. Among them, Python programming language gains a huge popularity and the reasons are as follows:

1. **Simple syntax & less coding**

* Python involves very less coding and simple syntax among other programming languages which can be used for developing AI applications. Due to the feature, the testing can be easier and we can focus more on programming.

2. **Inbuilt libaries for AI projects**

* A major advantage for using Python for AI is that it comes with inbuilt libararies. Python has libaries for almost all kinds of AI projects. For example, **NumPy**, **SciPy**, **matplotlib**, **nltk**, **SimpleAI** are some the important inbuilt libraries of Python.
    * **Open Source** - Python is an open source programming language. This makes it widely popular in the community.
    * **Can be used for broad range of programming** - Python can be used for a broad range of programming tasks like small shell script to enterprise web applications. This is another reason Python is suitable for AI projects.

## Features of Python
Python is a high-level, interpreted, interactive and object-oriented scripting language. Python is designed to be highly readable. It uses English keywords frequently where as other languages use punctuation, and it has fewer syntactical constructions than other languages. Python's features include the following:

* **Easy-to-learn** - Python was few keywords, simple structure, and a clearly defined syntax. This allows the student to pick up the language quickly. 
* **Easy-to-read** - Python code is more clearly defined and visible to the eyes. 
* **Easy-to-maintain** - Python's source code is fairly easy-to-maintain.
* **A broad standard libary** - Python's bulk of the libary is very portable and cross-platform compatible on UNIX, Windows, and Macintosh.
* **Interactive Mode** - Python has support for an interactive mode which allows interactive testing and debugging of snippets of code.
* **Portable** - Python can run on a wide variety of hardware platforms and has the same interface on all platforms.
* **Extendable** - We can add low-level modules to the Python interpreter. These modules enable programmers to add to or customize their tools to be more efficient.
* **Databases** - Python provides interfaces to all major commercial databases.
* **GUI Programming** - Python supports GUI applications that can be created and ported to many system calls, libaries and windows systems, such as Windows MFC, Macintosh, and the X Windows system of Unix.
* **Scalable** - Python provides a better structure and support for large programs than shell scripting.

### Important features of Python
Let us now consider the following important features of Python:

* It supports functional and structured programming methods as well as OOP.
* It can be used as a scripting language or can be compiled to byte-code for building large applications.
* It provides very high-level dynamic data types and supports dynamic type checking.
* It supports automatic garbage collection.
* It can be easily integrated with C, C++, COM, ActiveX, CORBA, and Java.

## Installing Python
Python distribution is available for a large number of platforms. You need to download only the binary code applicable for your platform and install Python.

If the binary code for your platform is not available, you need a C compiler to compile the source code manually. Compiling the source code offers more flexibility in term of choice of features that you require in your installation. 
Here is a quick overview of features that you require in your installation.

Here is quick overview of installing Python on various platforms:

1. **Unix and Linux installation**

* Follow these steps to install Python on Unix/Linux machine.
    * Open a Web browser and go to https://www.python.org/download
    * Follow the link to download zipped source code available for Unix/Linux.
    * Download and extract files.
    * Editing the *Modules/Setup* file if you want to customize some options.
    * run ./configure script
    * make
    * make install
* This installs Python at the standard location */usr/local/bin* and its libraries at */usr/local/lib/pythonXX* where XX is the version of Python.

2. **Windows Installation**

* Follow these steps to install Python on Windows machine. 
* Follow the link for the Windows installer *python-XYZ.msi* file  where XYZ is the version you need to install.
* To use this installer *python-XYZ.msi*, the Windows system must support Microsoft Installer 2.0. Save the installer file to your local machine and then run it to find out if your machine supports MSI..
* Run the downloaded file. This brings up the Python install wizard, which is really easy to use. Just accept the default settings and wait until the install is finished.

3. **Macintosh Installation**

* If you are on MAC OS X, it is recommended that you use Homebrew to install Python 3. It is a great package installer for Mac OS X and it is really easy to use. If you don't have Homebrew, you can install it using the following command:

```
$ ruby -e "$(curl -fsSL
https://raw.githubusercontent.com/Homebrew/install/master/install)"
```

We can update the package manager with the command below:

```
$ brew update
```

Now run the following command to install Python 3 on your system:

```
$ brew install python3
```

## Setting up PATH
Programs and other executable files can be in many directories, so operating systems provide a search path that lists the directories that the OS searches for executables.

The path is stored in an environment variable, which is a named string maintained by the operating system. This variable contains information available to the command shell and other programs.

The path variable is named as PATH in Unix or Path in Windows (Unix is case-sensitive, Windows is not).

In Mac OS, the installer handles the path details. To invoke the Python interpreter from any particular directory, you must add the Python directory to your path.

### Setting Path at Unix/Linux
To add the Python directory to the past for a particular session in Unix:

* In the csh shell

```
setenv PATH "$PATH:/usr/local/bin/python"
```

* In the bash shell (Linux)

```
export ATH = "$PATH:/usr/local/bin/python"
```

* In the sh or ksh shell

```
PATH = "$PATH:/usr/local/bin/python"
```

**Note**: /usr/local/bin/python is the path of the Python directory.

### Setting a Path at Windows
To add the Python directory to the path for a particular session in Windows:

* At the command prompt

```
path %path%;C:\Python
```

**Note**: C:\Python is the path of the Python directory.

## Running Python
Let us now see the different ways to run Python. The ways are described below:


### Interective Interpreter
We can start Python from Unix, DOS, or any other system that provides you a command-line interpreter or shell window.

* Enter **python** at the command line.
* Start coding right away in the interactive interpreter.

```
$python # Unix/Linux
```
Or
```
python% # Unix/Linux
```
Or
```
C:> python # Windows/DOS
```

Here is the list of all the available command line options:

| S.No. | Option & Description |
--- | --- |
| 1 | **-d** It provides debug output. |
| 2 | **-o** It generates optimized bytecode (resulting in .pyo files) |
| 3 | **-s** Do not run import site to look for Python paths on startup. |
| 4 | **-v** Verbose output (detailed trace on import statements). |
| 5 | **-x** Disables class-based built-in exceptions (just use strings), obsolete starting with version 1.6 |
| 6 | **-c cmd** Runs Python script sent in as cmd string. | 
| 7 | **File** Run Python script from given file. |

## Script from the Command-line
A Python script can be executed at the command line by invoking the interpreter on your application, as in the following:

```
$python script.py # Unix/Linux
```
or
```
python% script.py # Unix/Linux
```
or,
```
C:> python script.py # Windows/DOS
```

**Note:** Be sure the file permission mode allows execution.

## Integrated Development Environment
You can run Python from a Graphical User Interface (GUI) environment as well, if you have a GUI application on your system that support Python.

* **Unix** - IDLE is the very first Unix IDE for Python.
* **Windows** - PythonWin is the first Windows interface for Python and is an IDE with a GUI.
* **Macintosh** - The Macintosh version of Python along with the IDLE IDE is available from the main website, downloadable as either MacBinary or BinHex'd files.

If you are not able to set up the environment properly, then you can take help from your system admin. Make sure the Python environment is properly set up and working perfectly fine.

We can also use another Python platform called Anaconda. It includes hundreds of popular data science packages and the conda package and virtual environment manager for Windows, Linux, and MacOS. You can download it as per your operating system from the link https://www.anaconda.com/download/.

For this tutorial we are using Python 3.6.3 version on MS Windows.

# Machine Learning
Learning means the acquisition of knowledge or skills through study or experience. Based on this, we can define machine learning (ML) as follows:

It may be defined as the field of computer science, more specifically an application of artificial intelligence, which provides computer systems the ability to learn with data and improve from experience without being explicitly programmed.

Basically, the main focus of machine learning is to allow the computers learn automatically without human intervention. Now the question arises that how such learning can be started and done? It can be started with the observation of data. The data can be some examples, instruction or some direct experiences too. Then on the basis of this input, machine makes better decisions by looking for some patterns in data. 

## Types of Machine Learning (ML)
Machine Learning Algorithms helps computer system learn without being explicitly programmed. These algorithms are categorized into supervised or unsupervised. Let us now see a few algorithms:

### Supervised machine learning algorithms
This is the most commonly used machine learning algorithm. It is called supervised because the process of algorithm learning from the training dataset can be thought of as a teacher supervising the learning process. In this kind of ML algorithm, the possibile outcomes are already known and training data is also labeled with correct answers. It can be understood as follows:

Suppose we have input variables **x** and an output variable **y** and we applied an algorithm to learn the mapping function from the input to output such as:

```
Y = f(x)
```

Now, the main goal is to approximate the mapping function so well that when we have new input data (x), we can predict the output variable (Y) for that data.

Mainly supervised learning problems can be divided into the following two kinds of problems:

* **Classification** - A problem is called classification problem when we have the categorized output such as "black", "teaching", "non-teaching", etc.
* **Regression** - A problem is called regression problem when we have the real value output such as "distance", "kilogram", etc.

Decision tree, random forest, knn, logistic regression are the examples of supervised machine learning algorithms.

### Unsupervised machine learning algorithms
As the name suggests, these kind of machine learning algorithms do not have any supervisor to provide any sort of guidance. That is why unsupervised machine learning algorithms are closely aligned with what some call true artificial intelligence. It can be understood as follows:

Suppose we have input variable x, then there will be no corresponding output variables as there is in supervised learning algorithms.

In simple words, we can say that in unsupervised learning there will be no correct answer and no teacher for the guidance. Algorithms help to discover interesting patterns in data.

Unsupervised learning problems can be divided into the following two kinds of problems:

* **Clustering** - In clustering problems, we need to discover the inherent groupings in the data. For example, grouping customers by their purchasing behavior.
* **Association** - A problem is called association problem because such kinds of problem require discovering the rules that describe large portions of our data. For example, finding the customers who buy both **x** and **y**.

K-means for clustering, Apriori algorith, for association are the examples of unsupervised machine learning algorithms.

#### Reinforcement machine learning algorithms
These kinds of machine learning algorithms are used very less. These algorithms train the system to make specific decisions. Basically, the machine is exposed to an environment where it trains itself continually using the trial and error method. These algorithms learn from past experience and tries to capture the best possible knowledge to make accurate decisions. Markov Decision Process is an example of reinforcement machine learning algorithms.

## Most Common Machine Learning Algorithms
In this section, we will learn about the most common machine learning algorithms. The algorithms are described below:

### Linear Regression
It is one of the most well-known algorithms in statistics and machine learning.

Basic concept - Mainly linear regression is a linear model that assumes a linear relationship between the input variables say x and the single output variable say y. In other words, we can say that y can be calculated from a linear combination of the input variables x. The relationship between variables can be established by fitting a best line. 

#### Types of Linear Regression
Linear regression is of the following two types:

* **Simple linear regression**. A linear regression algorithm is called simple linear regression if it is having only one independent variable.
* **Multiple linear regression**. A linear regression algorithm is called multiple linear regression if it is having more than one independent variable.

Linear regression is mainly used to estimate the real values based on continuous variable(s). For example, the total sale of a shop in a day, based on real values, can be estimated by linear regression.

### Logic Regression
It is a classification algorithm and also known as **logit** regression.

Mainly logistic regression is a classification algorithm that is used to estimate the discrete values like 0 or 1, true or false, yes or no based on given set of independent variable. Basically, it predicts the probability hence its output lies in between 0 and 1.

### Decision Tree
Decision tree is a supervised learning algorithm that is mostly used for classification problems. 

Basically it is a classifier expressed as recursive partition based on the independent variables. Decision tree has nodes which form the rooted tree. Rooted tree is a direccted tree with a node called "root". Root does not have any incoming edges and all the other nodes have one incoming edge. These nodes are called leaves or decision nodes. For example, consider the following decision tree to see whether a person is fit or not.

### Support Vector Machine (SVM)
It is used for both classification and regression problems. But mainly it is used for classification problems. The main concept of SVM is to plot each data item as a point in n-dimensional space with the value of each feature being the value of a particular coordinate. Here n would be the features we would have. Following is a simple graphical representation to undestand the concept of SVM.

![03 Vectors](https://user-images.githubusercontent.com/124214430/222920396-87f8bf9b-2415-45eb-91fd-26cba15e6d63.png)

In the above diagram, we have two features hence we first need to plot these two variables in two dimensional space where each point has two coordinates, called support vectors. The line splits the data into two different classified groups. This line would be the classifier.

### Naive Bayes
It is also a classification technique. The logic behind this classification technique is to use Bayes theorem for building classifiers. The assumption is that the predictors are independent. In simple words, it assumes that the presence of a particular feature in a class in unrelated to the presence of any other feature. Below is the equation for Bayes theorem:

```
$$P\left (\frac{A}{B}\right) = \frac{P\left (\frac{B}{A}\right)P\left (A \right)}{P\left (B \right)}$$
```

The Naive Bayes model is easy to build and particularly useful for large data sets.

### K-Nearest Neighbors (KNN)
It is used for both classification and regression of the problems. It is widely used to solve classification problems. The main concept of the algorithm is that it used to store all the available cases and classifies new cases by majority votes of its k neighbors. The case being then assigned to the class which is the most common amongst its K-nearest neighbors, measured by a distance function. The distance function can be Euclidean, Minkowski and Hamming distance. Consider the following to use KNN:

* Computationally KNN are expensive than other algorithms used for classification problems.
* The normalization of variables needed otherwise higher range variables can bias it.
* In KNN, we need to work on pre-processing stage like noise removal.

### K-Means Clustering
As the name suggests, it is used to solve clustering problems. It is basically a type of unsupervised learning. The main logic of K-Means clustering algorithm is to classify the data set through a number of clusters. Follow these stpes to form clusters by K-means:

* K-means picks k number of points for each cluster known as centroids.
* Now each data point forms a cluster with the closest centroids, i.e., k clusters.
* Now, it will find the centroids each cluster based on the existing cluster members.
* We need to repeat these steps until convergence occurs.

### Random Forest
It is a supervised classification algorithm. The advantage of random forest algorithm is that it can be used for both classification and regression kind of problems. Basically it is the collection of decision trees (i.e., forest) or you can say ensemble of the decision trees. The basic concept of random forest is that each tree gives a classification and the forest chooses the best classifications from them. Followings are the advantages of Random Forest algorithm:

* Random forest clasifier can be used for both classification and regression tasks.
* They can handle the missing values.
* It won't over fir the model even if we have more number of trees in the forest. 

# Data Preparation
We have already studied supervised as well as unsupervised machine learning algorithms. These algorithms require formatted data to start the training process. We must prepare or format data in a certain way so that it can be supplied as an input to ML algorithms. 

This chapter focuses on data preparation for machine learning algorithms.

## Preprocessing the Data
In our daily life, we deal with lots of data but this data is in raw form. To provide the data as the input of machine learning lagorithms, we need to convert it into a meaningful data. That is where data preprocessing comes into picture. In other simple words, we can say that before providing the dta to the machine learning algorithms w need to preprocess the data.

### Data preprocessing steps
Follow these steps to preprocess the data in Python:

**Step 1 - Importing the useful packages** - If we are using Python then this would be the first step for converting the data into a certain format, i.e., preprocessing it can be done as follows:

```
import numpy as np
import sklearn.preprocessing
```
Have we have used the following two packages:

* **NumPy** - Basically NumPy is a general purpose array-processing package designed to efficiently manipulate large multi-dimentional arrays of arbitrary records without sacrificing to much speed for small multi-dimentional arrays.
* **Sklearn.preprocessing** - This package provides many common utility functions and transformer classes to change raw feature vectors into a representaion that is more suitable for machine learning algorithms.

**Step 2 - Defining sample data** - After importing the packages, we need to define some sample data so that we can apply preprocessing techniques on that data. We will now define the following sample data:

```
Input_data = np.array([2.1,  -1.9,  5.5],
                      [-1.5,  2.4   3.5],
                      [0.5,  -7.9,  5.6],
                      [5.9,   2.3, -5.8],)
```

**Step3 - Applying preprocessing technique** - In this step, we need to applyany of the preprocessing techniques.

The following section describes the data preprocessing techniques.

## Techniques for Data Preprocessing
The techniques for data preprocessing are described below:

### Binarization
This is the preprocessing technique which is used when we need to convert our numerical values into Boolean values. We can use an inbuilt method to binarize the input data say by using 0.5 as the threshold value in the following way:

```
data_binarized = preprocessing.Binarizer(threshold = 0.5).transform
print("\nBinarized data:\n", data_binarized)
```
Now after running the above code we will get the following output, all the values above 0.5(threshold values) would be converter to 1 and al the values below 0.5 would be converted to 0.

#### Binarized data

```
[[ 1.  0.  1.]
 [ 0.  1.  1.]
 [ 0.  0.  1.]
 [ 1.  1.  0.]]
```

### Mean Removal
It is another very common preprocessing technique that is used in machine learning. Basically it is used to eliminate the mean from feature vector so that every feature is centered on zero. We can also remove the bias from the feature in the feature vector. For applying mean removal preprocessing technique on the sample data, we can write the Python code shown below. The code will display the Mean and Standard deviation of the input data:

```
print("Mean = ", input_data.mean(axis = 0))
print("Std deviation = ", input_)data.std(axis = 0)
```

We will get the following output after running the above line of code:

```
         Mean = [1.75      -1.275      2.2]
Std deviation = [2.71431391 4.20022321 4.69414529]
```

Now, the code below will remove the Mean and Standard deviation of the input data:

```
data_scaled = preprocessing.scale(input_data)
print("Mean =", data_scaled.mean(axis=0))
print("Std deviation =", data_scaled.std(axis = 0))
```

We will get the following output after running the above lines of code:

```
         Mean = [1.110022302e-16 0.0000000e+00 0.0000000e+00]
Std deviation = [1.              1.            1.]
```

### Scaling 
It is another data preprocessing technique that is used to scale the feature vectors. Scaling of feature vectors is needed because the values of every feature can vary between many random values. In other words we can say that scaling is important because we do not want any feature to be synthetically large or small. With the help of the following Python code, we can do the scalling of our input data, i.e. feature vector:


#### Min max scaling

```
data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1))
data_scaled_minmax = data_scaler_minmax.fit_transform(input_data)
print ("\nMin max scaled data:\n", data_scaled_minmax)
```

We will get the following output after running the above lines of code:

#### Min max scaled data

```
[ [ 0.48648649  0.58252427  0.99122807]
  [ 0.          1.          0.81578947]
  [ 0.27027027  0.          1.        ]
  [ 1.          0.99029126  0.        ] ]
```

### Normalization
It is another data preprocessing technique that is used to modify the feature vectors. Such kind of modification is necessary to measure the feature vectors on a common scale. Followings are two types of normalization which can be used in machine learning:

#### L1 Normalization
It is also referred to as **Least Absolute Deviations**. This kind of normalization modifies the values so that the sum of the abolute values is always up to 1 in each row it can be implemented on the input data with the help of the following Python code:

```
# Normalize data
data_normalized_l1 = preprocessing.normalize(input_data, norm ='l1')
print("\nL1 normalized data:\n", data_normalized_l1)
```

The above line of code generates the following output & miuns;

```
L1 normalized data:
[[  0.22105236   -0.2           0.57894737]
 [ -0.2027027     0.342432432   0.47297297]
 [  0.03571429   -0.54628571    0.4       ]
 [  0.42142857    0.16428571   -0.41428571]]
```

#### L2 Normalization
It is also referred to as **least squares**. This kind of normalization modifies the vlues so that the sum of the squares is always up to 1 in each row. It can be implemented on the input data with the help of the following Python code:

```
# Normalize data
data_normalized_l2 = preprocessing.normalize(input_data, norm = '12')
print("\nL2 normalized data :\n", data_normalized_l2)
```

The above line of code will generate the following output:

```
L2 normalized data:
[[ 0.33946114   -0.30713151     0.88906489]
 [-0.33325106    0.53320169     0.7775858 ]
 [ 0.05156558   -0.81473612     0.57753446]
 [ 0.68706914    0.26784051    -0.6754239 ]]
```



# Reference

* [Artificial Intelligence - Quick Guide](https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_quick_guide.htm#)
* [Basics of Artificial Intelligence (AI)](https://prutor.ai/ai-with-python-prime-concept/)
* [Inductive Reasoning](https://www.scribbr.com/methodology/inductive-reasoning/)
* [What Is Deductive Reasoning?](https://www.scribbr.com/methodology/deductive-reasoning/)
